{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jbXxM5WINXX"
   },
   "outputs": [],
   "source": [
    "test_data_dir = \"../data/test_data_roi/\"\n",
    "submission_format_file = \"../submissions/submission_format.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIdpoVOMTJ8J"
   },
   "outputs": [],
   "source": [
    "models_dir = \"../models/\"\n",
    "\n",
    "# model_name = \"R3D\"\n",
    "# model_name = \"MC3\"\n",
    "model_name = \"R(2+1)D_v1\"\n",
    "# model_name = \"R(2+1)D_v2\"\n",
    "\n",
    "model_path_dict = {\n",
    "    \"R3D\": models_dir + \"R3D/model_v67_epoch_27_mcc_0.7801_acc_0.9635_loss0.1248.pth\",\n",
    "    \"MC3\": models_dir + \"MC3/model_v66_epoch_28_mcc_0.7989_acc_0.9673_loss0.1125.pth\",\n",
    "    \"R(2+1)D_v1\": models_dir + \"R(2+1)D_v1/model_v65_epoch_28_mcc_0.769_acc_0.9635_loss0.1323.pth\",\n",
    "    \"R(2+1)D_v2\": models_dir + \"R(2+1)D_v2/model_v72_epoch_28_mcc_0.7306_acc_0.9572_loss0.1684.pth\",\n",
    "}\n",
    "model_path = model_path_dict[model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i79MrkJvIzFS"
   },
   "outputs": [],
   "source": [
    "class VideoIterator(Dataset):\n",
    "    def __init__(self, data_dir, data_csv, transforms, device):\n",
    "        self.df = pd.read_csv(data_csv)\n",
    "        self.df[\"path\"] = data_dir + self.df[\"filename\"]\n",
    "        self.transforms = transforms\n",
    "        self.device = device\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        x = []\n",
    "        video = cv2.VideoCapture(row[\"path\"])\n",
    "        if not video.isOpened():\n",
    "            print(\"Error opening video file!\")\n",
    "        while video.isOpened():\n",
    "            ret, frame = video.read()\n",
    "            if ret:\n",
    "                x.append(self.transforms(frame))\n",
    "            else:\n",
    "                break\n",
    "        video.release()\n",
    "        x = torch.stack(x)\n",
    "        x = x.permute(1, 0, 2, 3)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = x.to(self.device, dtype=torch.float)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqc8vq4OI-l_"
   },
   "outputs": [],
   "source": [
    "class R2plus1dModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2plus1dModel, self).__init__()\n",
    "\n",
    "        self.cnn = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "        self.cnn.fc = nn.Linear(in_features=512,\n",
    "                                out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.cnn(input)\n",
    "        x = self.sig(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Rmc3Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Rmc3Model, self).__init__()\n",
    "\n",
    "        self.cnn = torchvision.models.video.mc3_18(pretrained=False)\n",
    "        self.cnn.fc = nn.Linear(in_features=512,\n",
    "                                out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.cnn(input)\n",
    "        x = self.sig(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class R3dModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R3dModel, self).__init__()\n",
    "\n",
    "        self.cnn = torchvision.models.video.r3d_18(pretrained=False)\n",
    "        self.cnn.fc = nn.Linear(in_features=512,\n",
    "                                out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.cnn(input)\n",
    "        x = self.sig(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2091403,
     "status": "ok",
     "timestamp": 1590353202334,
     "user": {
      "displayName": "Onac Laura",
      "photoUrl": "https://lh5.googleusercontent.com/-C7_Vw3IuYEw/AAAAAAAAAAI/AAAAAAAAB_8/KxZJzsDC49Q/s64/photo.jpg",
      "userId": "03526298879016517976"
     },
     "user_tz": -180
    },
    "id": "YZeYHqBcJBkz",
    "outputId": "84bb93ac-0b2e-4a87-fe05-ebf2afddd383"
   },
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989])\n",
    "])\n",
    "\n",
    "data_iterator = VideoIterator(test_data_dir, submission_format_file, transformations, device)\n",
    "print(len(data_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model architecture here:\n",
    "model_class_dict = {\n",
    "    \"R3D\": R3dModel,\n",
    "    \"MC3\": Rmc3Model,\n",
    "    \"R(2+1)D_v1\": R2plus1dModel,\n",
    "    \"R(2+1)D_v2\": R2plus1dModel,\n",
    "}\n",
    "\n",
    "model = model_class_dict[model_name]().to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for j, x in enumerate(data_iterator):\n",
    "        if j % 200 == 0:\n",
    "            print(j)\n",
    "        outputs = model(x)\n",
    "        p = outputs[0].item()\n",
    "        y_pred.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Hyu9270W2vu"
   },
   "outputs": [],
   "source": [
    "subm_file =  f\"../submissions/inference_{model_name}.csv\"\n",
    "\n",
    "df = data_iterator.df.copy(deep=False)\n",
    "\n",
    "df[\"stalled\"] = y_pred\n",
    "df = df[[\"filename\", \"stalled\"]]\n",
    "\n",
    "df.to_csv(subm_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}